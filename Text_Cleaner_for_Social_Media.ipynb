{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìå‚ÄØGoal: Clean unstructured text by removing:\n",
        "\n",
        "**URLs (e.g. https://google.com)**\n",
        "\n",
        "**Mentions (@username)**\n",
        "\n",
        "**Hashtags (#topic)**\n",
        "\n",
        "**Emojis**\n",
        "\n",
        "**Extra spaces**\n",
        "\n",
        "**Stopwords (optional)**\n",
        "\n",
        "# üì¶‚ÄØTools used:\n",
        "\n",
        "re**gex (re): to search and replace patterns like URLs, hashtags, etc.**\n",
        "\n",
        "**nltk: for stopword removal**"
      ],
      "metadata": {
        "id": "5KYQ5HcjSMGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "TLv63dkrSWlu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords (only the first time)\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji2NcEQnScf9",
        "outputId": "00195e2f-eebb-433b-b9ff-178bd70cfba5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "Mok5TdnpSzcA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_social_media_text(text):\n",
        "    # Remove URLs (http/https)\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "\n",
        "    # Remove mentions but keep the name\n",
        "    text = re.sub(r\"@(\\w+)\", r\"\\1\", text)\n",
        "\n",
        "    # Remove hashtags (but keep the word)\n",
        "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
        "\n",
        "    # Remove emojis and non-ASCII characters\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Remove stopwords (optional)\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Join back into cleaned sentence\n",
        "    cleaned_text = \" \".join(filtered_words)\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "As4ujTtcSk4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "sample_text = \"Hey @john! Check this out üòéüî•: https://t.co/example #awesome #AIrocks\"\n",
        "cleaned = clean_social_media_text(sample_text)\n",
        "print(\"Cleaned Text:\", cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lraFgHQSoSr",
        "outputId": "d55e8979-61ad-4552-ef42-873917c0df6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: Hey john! Check : awesome AIrocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Why We Use These Functions:\n",
        "### ***Function\tPurpose***\n",
        "* re.sub(r\"http\\S+\twww\\S+\", \"\", text)\n",
        "* re.sub(r\"@\\w+\", \"\", text)\tRemoves mentions like @user123\n",
        "* re.sub(r\"#(\\w+)\", r\"\\1\", text)\tRemoves the # symbol but keeps the word (e.g., \"#AI\" ‚Üí \"AI\")\n",
        "* re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\tRemoves emojis and any non-English characters\n",
        "* re.sub(r\"\\s+\", \" \", text).strip()\tRemoves extra spaces and trims the text\n",
        "stopwords.words('english')\tRemoves common unimportant words like \"the\", \"is\", \"and\""
      ],
      "metadata": {
        "id": "Q4Hjk3qmTMYM"
      }
    }
  ]
}